{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "Target dataset- VGG Flowers\n",
    "#Classes : 102\n",
    "#Total number of images: 1002\n",
    "Approx 10 images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "#image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                          data_transforms[x])\n",
    "#                  for x in ['train', 'val']}\n",
    "#dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "#                                             shuffle=True, num_workers=4)\n",
    "#              for x in ['train', 'val']}\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='train', transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root='val', transform=val_transforms)\n",
    "valloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "#dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "#class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    accuracy = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        #print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs,labels in trainloader:\n",
    "\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            else:\n",
    "                model.eval()  # Set model to training mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs,labels in valloader:\n",
    "\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects = torch.sum(preds == labels.data)\n",
    " \n",
    "                epoch_loss = running_loss / 1020\n",
    "                epoch_acc = running_corrects.double() / 1020\n",
    "        \n",
    "                if epoch%25 == 0:\n",
    "                    print(\"Epoch \"+str(epoch)+\" complete, accuracy: \"+str(epoch_acc))\n",
    "                #print(epoch_acc)\n",
    "                accuracy.append((epoch,epoch_acc.cpu().numpy()))\n",
    "            \n",
    "            #print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return (model,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the convnet\n",
    "----------------------\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 102)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=40, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete, accuracy: tensor(0.0588, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 25 complete, accuracy: tensor(0.0588, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model_ft, accuracy = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.array(accuracy).ravel().reshape(100,2)\n",
    "np.savetxt(\"finetune_train_128_0.001.csv\", accuracy, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet as fixed feature extractor\n",
    "----------------------------------\n",
    "\n",
    "Here, we need to freeze all the network except the final layer. We need\n",
    "to set ``requires_grad == False`` to freeze the parameters so that the\n",
    "gradients are not computed in ``backward()``.\n",
    "\n",
    "You can read more about this in the documentation\n",
    "`here <https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 102)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=25, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "On CPU this will take about half the time compared to previous scenario.\n",
    "This is expected as gradients don't need to be computed for most of the\n",
    "network. However, forward does need to be computed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete, accuracy: tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 25 complete, accuracy: tensor(0.0510, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 50 complete, accuracy: tensor(0.0578, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 75 complete, accuracy: tensor(0.0569, device='cuda:0', dtype=torch.float64)\n",
      "Training complete in 2m 56s\n",
      "Best val Acc: 0.057843\n"
     ]
    }
   ],
   "source": [
    "model_conv, accuracy_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_conv = np.array(accuracy_conv).ravel().reshape(100,2)\n",
    "np.savetxt(\"featext_train_128_.00001.csv\", accuracy_conv, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall for both cases, the validation accuracy is poor (~6%). This might be because of the size of the dataset- each class has hardly 10 images to train on. Thus, the model is not accurate overall. \n",
    "\n",
    "Finetuning: For the three starting learning rates explored, l = 0.0001 appears to give the best performance.\n",
    "Feature Extractor: For the three starting learning rates explored, l = 0.001 appears to give the best performance.\n",
    "\n",
    "Comparison between FineTuning, Feature extraction:\n",
    "Feature extraction performs better than FineTuning. \n",
    "This can be attributed to the fact that while FineTuning, we propagate the loss through to all the layers. Thus, the features the model learnt while training on the original ImageNet dataset are lost. The new set of features do not have enough data to predict properly. \n",
    "However, while we use it as a feature extractor, the first n-1 layers are undisturbed- they effeciently extract the features, based on which the last layer acts similar to a regression model to train on. Thus, it performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
